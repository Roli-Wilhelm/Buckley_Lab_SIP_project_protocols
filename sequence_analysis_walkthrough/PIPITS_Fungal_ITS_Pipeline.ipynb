{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPITS Fungal ITS-dedicated Pipeline\n",
    "\n",
    "* DADA2 can, in theory, process ITS data. This is a dedicated alternative\n",
    "\n",
    "\n",
    "### Dependencies ####\n",
    "\n",
    "##### || PIPITS ||\n",
    "* Follow instructions provided at: \n",
    "* https://github.com/hsgweon/pipits\n",
    "* Note: all dependencies which require 'sudo' will already be met (i.e. don't bother running those commands... they won't work anyways)\n",
    "\n",
    "##### || deML ||\n",
    "* Follow instructions provided at: \n",
    "* https://github.com/grenaud/deML\n",
    "\n",
    "##### || phyloseq ||\n",
    "* conda install -c r-igraph \n",
    "* Rscript -e \"source('http://bioconductor.org/biocLite.R');biocLite('phyloseq')\" \n",
    "\n",
    "##### || FUNGuild ||\n",
    "* download FUNGUild script:\n",
    "* https://raw.githubusercontent.com/UMNFuN/FUNGuild/master/Guilds_v1.1.py\n",
    "\n",
    "### Citations ###\n",
    "* Gweon, H. S., Oliver, A., Taylor, J., Booth, T., Gibbs, M., Read, D. S., et al. (2015). PIPITS: an automated pipeline for analyses of fungal internal transcribed spacer sequences from the Illumina sequencing platform. Methods in ecology and evolution, 6(8), 973-980.\n",
    "\n",
    "* Renaud, G., Stenzel, U., Maricic, T., Wiebe, V., & Kelso, J. (2014). deML: robust demultiplexing of Illumina sequences using a likelihood-based approach. Bioinformatics, 31(5), 770-772.\n",
    "\n",
    "* McMurdie and Holmes (2013) phyloseq: An R Package for Reproducible Interactive Analysis and Graphics of Microbiome Census Data. PLoS ONE. 8(4):e61217\n",
    "\n",
    "* Nguyen NH, Song Z, Bates ST, Branco S, Tedersoo L, Menke J, Schilling JS, Kennedy PG. 2016. FUNGuild: An open annotation tool for parsing fungal community datasets by ecological guild. Fungal Ecology 20:241â€“248.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### Last Modified by R. Wilhelm on October 12th, 2017 ######\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Provide the directory for your index and read files\n",
    "ITS = '/home/roli/APHID_ITS/aphids/'\n",
    "\n",
    "# Provide \n",
    "datasets = [['aphid',ITS,'mapping_file.txt']]\n",
    "\n",
    "# Ensure your reads files are named accordingly (or modify to suit your needs)\n",
    "readFile1 = 'read1.fq.gz'\n",
    "readFile2 = 'read2.fq.gz'\n",
    "indexFile1 = 'index_read1.fq.gz'\n",
    "indexFile2 = 'index_read2.fq.gz'\n",
    "\n",
    "# Example of metadata file\n",
    "#Index1\tIndex2\tName\n",
    "#AATTCAA\tCATCCGG\tRG1\n",
    "#CGCGCAG\tTCATGGT\tRG2\n",
    "#AAGGTCT\tAGAACCG\tRG3\n",
    "#ACTGGAC\tTGGAATA\tRG4\n",
    "\n",
    "## Again, for our pipeline Index1 typically is the reverse complement of the reverse barcode, while Index2 is the forward barcode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Demultiplex Raw Reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/home/roli/FORESTs_BHAVYA/WoodsLake/raw_seq/ITS//pipits_input/unknown*': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# Ignore all the 'conflict' errors. The reads are paired so the conflicts are bogus (i.e. it gives a warning everytime an barcode appears in multiple samples, but no pairs are duplicated)\n",
    "\n",
    "for dataset in datasets:\n",
    "    name = dataset[0]\n",
    "    directory = dataset[1]\n",
    "    metadata = directory+dataset[2]\n",
    "    index1 = directory+indexFile1\n",
    "    index2 = directory+indexFile2\n",
    "    read1 = directory+readFile1\n",
    "    read2 = directory+readFile2\n",
    "    \n",
    "    # Make output directory\n",
    "    %mkdir $directory/pipits_input/\n",
    "    \n",
    "    # Run deML   ## Note: you may get error involving 'ulimit'. If so, exit your notebook. Enter 'ulimit -n 9999' at the command line, then restart a new notebook.\n",
    "    !deML -i $metadata -f $read1 -r $read2 -if1 $index1 -if2 $index2 -o $directory/pipits_input/$name\n",
    "\n",
    "    # Remove unnecessary 'failed' reads and index files\n",
    "    %rm $directory/pipits_input/*.fail.* $directory/pipits_input/unknown*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Make Sample Mapping File (aka. 'readpairlist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ]
    }
   ],
   "source": [
    "import glob, re\n",
    "for dataset in datasets:\n",
    "    name = dataset[0]\n",
    "    directory = dataset[1]\n",
    "    \n",
    "    # Remove Previously Prepended Name (PIPITS wanted something)\n",
    "    for file in glob.glob(directory+\"pipits_input/\"+name+\"_*\"):\n",
    "        new_name = re.sub(name+\"_\",\"\",file)\n",
    "        os.rename(file, new_name)\n",
    "    \n",
    "    # Rename files with with extension .fq (PIPITS is PICKY)\n",
    "    for file in glob.glob(directory+\"pipits_input/*.fq.gz\"):\n",
    "        new_name = re.sub(\".fq.gz\",\".fastq.gz\",file)\n",
    "        os.rename(file, new_name)\n",
    "    \n",
    "    # Remove Unbinned Reads\n",
    "    %rm $directory/pipits_input/unknown*        \n",
    "    \n",
    "    # Run PIPITS List Prep\n",
    "    input_dir = directory+\"pipits_input/\"\n",
    "    output_dir = directory+name+\".readpairslist.txt\"\n",
    "    \n",
    "    !pipits_getreadpairslist -i $input_dir -o $output_dir -f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Pre-process Data with PIPITS (merge and QC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    name = dataset[0]\n",
    "    directory = dataset[1]\n",
    "    \n",
    "    input_dir = directory+\"/\"\n",
    "    output_dir = directory+\"pipits_prep/\"\n",
    "    readpairfile = directory+name+\".readpairslist.txt\"\n",
    "    \n",
    "    !pipits_prep -i $input_dir -o $output_dir -l $readpairfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Extract Variable Region (**User Input Required**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "ITS_Region = \"ITS1\"\n",
    "\n",
    "for dataset in datasets:\n",
    "    name = dataset[0]\n",
    "    directory = dataset[1]\n",
    "    \n",
    "    input_file = directory+\"pipits_prep/prepped.fasta\"\n",
    "    output_dir = directory+\"pipits_funits/\"\n",
    "    \n",
    "    !pipits_funits -i $input_file -o $output_dir -x $ITS_Region \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Cluster and Assign Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    name = dataset[0]\n",
    "    directory = dataset[1]\n",
    "    \n",
    "    input_file = directory+\"pipits_funits/ITS.fasta\"\n",
    "    output_dir = directory+\"PIPITS_final/\"\n",
    "\n",
    "    !pipits_process -i $input_file -o $output_dir --Xmx 20G\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Push OTU Table through FUNGuild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    name = dataset[0]\n",
    "    directory = dataset[1]\n",
    "    \n",
    "    # Prepare PIPITS output for FUNGuild\n",
    "    !pipits_funguild.py -i $directory/PIPITS_final/otu_table.txt -o $directory/PIPITS_final/otu_table_funguild.txt\n",
    "   \n",
    "    # Run FUNGuild\n",
    "    !python /home/db/FUNGuild/Guilds_v1.1.py -otu $directory/PIPITS_final/otu_table_funguild.txt -db fungi -m -u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Import into R   (WORK IN PROGRESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "## Setup R-Magic for Jupyter Notebooks\n",
    "import rpy2\n",
    "import pandas as pd\n",
    "%load_ext rpy2.ipython\n",
    "%R library(phyloseq)\n",
    "%R library(ape)\n",
    "\n",
    "def fix_biom_conversion(file):\n",
    "    with open(file, 'r') as fin:\n",
    "        data = fin.read().splitlines(True)\n",
    "    with open(file, 'w') as fout:\n",
    "        fout.writelines(data[1:])\n",
    "        \n",
    "for dataset in datasets:\n",
    "    name = dataset[0]\n",
    "    directory = dataset[1]\n",
    "   \n",
    "    # Import Taxonomy File\n",
    "    !gunzip $directory\"/PIPITS_final/assigned_taxonomy.txt.gz\"\n",
    "    tax_file = pd.read_csv(directory+\"/PIPITS_final/assigned_taxonomy.txt\", sep=\"\\t\")\n",
    "    %R -i tax_file\n",
    "    %R tax_file <- tax_file[sort(row.names(tax_file)),] #read names must match the count_table\n",
    "    !gzip $directory\"/PIPITS_final/assigned_taxonomy.txt\"\n",
    "    \n",
    "    # Import Counts Data\n",
    "    !gunzip $directory\"/PIPITS_final/otu_table.txt.gz\"\n",
    "    fix_biom_conversion(directory+\"/output/\"+name+\".counts.final.tsv\") # The biom converter adds a stupid line that messes with the table formatting\n",
    "    count_table = pd.read_csv(directory+\"/PIPITS_final/otu_table.txt\", sep=\"\\t\")\n",
    "    %R -i count_table\n",
    "    %R rownames(count_table) = count_table$X.OTU.ID   \n",
    "    #%R count_table$X.OTU.ID <- NULL    \n",
    "    %R count_table <- count_table[sort(row.names(count_table)),] #read names must match the tax_table\n",
    "    !gzip $directory\"/PIPITS_final/otu_table.txt\"\n",
    "\n",
    "    # Import Sample Data\n",
    "    sample_file = pd.read_table(directory+metadata, keep_default_na=False)\n",
    "    %R -i sample_file\n",
    "    %R rownames(sample_file) = sample_file$X.SampleID   \n",
    "    %R sample_file$X.SampleID <- NULL\n",
    "    %R sample_file$LinkerPrimerSequence <- NULL  ## Clean-up some other stuff\n",
    "    \n",
    "    # Convert to Phyloseq Objects\n",
    "    %R p_counts = otu_table(count_table, taxa_are_rows = TRUE)    \n",
    "    %R p_tax = tax_table(tax_file)\n",
    "    %R taxa_names(p_tax) <- rownames(tax_file) # phyloseq throws out rownames\n",
    "    %R colnames(p_tax) <- colnames(tax_file) # phyloseq throws out colnames\n",
    "    \n",
    "    # Merge Phyloseq Objects\n",
    "    %R p_final = phyloseq(p_counts, p_tax)\n",
    "\n",
    "    # Save Phyloseq Object as '.rds'\n",
    "    #output = directory+\"/output/p_\"+name+\".pipits.final.rds\"\n",
    "    #%%R -i output\n",
    "    #%%R saveRDS(p_final, file = output)\n",
    "    \n",
    "    # Confirm Output\n",
    "    #%%R print(p_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
     ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "print(head(tax_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Clean-up Intermediate Files and Final Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    name = dataset[0]\n",
    "    directory = dataset[1]\n",
    "   \n",
    "    %rm -r $directory/pipits_prep/\n",
    "    %rm -r $directory/pipits_funits/\n",
    "    %rm -r $directory/pipits_input/\n",
    "    \n",
    "    del_me = directory+name+\".readpairslist.txt\"\n",
    "    %rm $del_me"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": true,
  "kernelspec": {
   "display_name": "Environment (conda_qiime2-2017.9)",
   "language": "python",
   "name": "conda_qiime2-2017.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
