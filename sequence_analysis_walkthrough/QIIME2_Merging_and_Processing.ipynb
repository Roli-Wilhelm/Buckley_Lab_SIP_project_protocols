{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Pipeling to Merge Sequencing Libraries from Different Sequencing Runs that have been denoised by DADA2  and Finish with the Standard Processing Pipeline###\n",
    "* Merge multiple libraries for the *SAME* sequencing region (i.e. ITS+ITS... or SSU+SSU...)\n",
    "* Complete remainder of processing pipieline: prepare Rep Seqs, Classify Seqs, Make Tree, Make Phyloseq Object\n",
    "\n",
    "*Informed by the \"Fecal Microbiota Transplant Tutorial\" for QIIME2*\n",
    "\n",
    "### Commands to Install Dependencies ####\n",
    "##### || QIIME2 ||\n",
    "* conda create -n qiime2-2017.9 --file https://data.qiime2.org/distro/core/qiime2-2017.9-conda-linux-64.txt  \n",
    "\n",
    "* source activate qiime2-2017.9\n",
    "\n",
    "##### || rpy2 (don't use conda version) ||\n",
    "* pip install rpy2  \n",
    "\n",
    "##### || phyloseq ||\n",
    "* conda install -c r-igraph \n",
    "* Rscript -e \"source('http://bioconductor.org/biocLite.R');biocLite('phyloseq')\" \n",
    "\n",
    "##### || R packages ||\n",
    "* ape   (natively installed with in conda environment)\n",
    "\n",
    "\n",
    "###### Last Modified by R. Wilhelm on October 12th, 2017 ######\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, re\n",
    "\n",
    "# Provide the directory where files are located \n",
    "directory = '/home/roli/FORESTs_BHAVYA/Combined_Libraries/ITS/'\n",
    "\n",
    "# Provide a list of all the FeatureTables you will merge\n",
    "# Produced by QIIME2 in STEP 7 (i.e. DADA2 Denoising/Merging/FeatureTable)\n",
    "#qva_files = ['ITS.table.Honnedaga.qza','ITS.table.Woods.qza']\n",
    "qva_files = ['ITS.table.1.qza','ITS.table.2.qza','ITS.table.3.qza','ITS.table.4.qza']\n",
    "\n",
    "# Provide a list of all the Representative Sequences you will merge\n",
    "# Also produced from STEP 7 (i.e. DADA2 Denoising/Merging/FeatureTable)\n",
    "#seq_files = ['ITS.rep.seqs.Honnedaga.qza','ITS.rep.seqs.Woods.qza']\n",
    "seq_files = ['ITS.rep.seqs.1.qza','ITS.rep.seqs.2.qza','ITS.rep.seqs.3.qza','ITS.rep.seqs.4.qza']\n",
    "\n",
    "# Provide a concatenated metadatafile with matching column order\n",
    "metadata = 'ITS.metadata.combined.tsv'\n",
    "\n",
    "## Enter Minimum Support for Keeping QIIME Classification\n",
    "# Note: Classifications that do not meet this criteria will simply be retained, but labeled 'putative'\n",
    "min_support = 0.8\n",
    "\n",
    "domain = 'fungi'   # 'bacteria' | 'fungi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Merge Feature Tables using QIIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qiime feature-table merge --i-table1 /home/roli/FORESTs_BHAVYA/Combined_Libraries/ITS//ITS.table.1.qza --i-table2 /home/roli/FORESTs_BHAVYA/Combined_Libraries/ITS//ITS.table.2.qza --o-merged-table /home/roli/FORESTs_BHAVYA/Combined_Libraries/ITS//output/merged.table.final.qza\n",
      "\n",
      "qiime feature-table merge-seq-data --i-data1 /home/roli/FORESTs_BHAVYA/Combined_Libraries/ITS//ITS.rep.seqs.1.qza --i-data2 /home/roli/FORESTs_BHAVYA/Combined_Libraries/ITS//ITS.rep.seqs.2.qza --o-merged-data /home/roli/FORESTs_BHAVYA/Combined_Libraries/ITS//output/merged.rep.seqs.final.qza\n",
      "\n",
      "qiime feature-table merge --i-table1 /home/roli/FORESTs_BHAVYA/Combined_Libraries/ITS//output/merged.table.final.qza --i-table2 /home/roli/FORESTs_BHAVYA/Combined_Libraries/ITS//ITS.table.3.qza --o-merged-table /home/roli/FORESTs_BHAVYA/Combined_Libraries/ITS//output/merged.table.final.qza\n",
      "\n",
      "qiime feature-table merge-seq-data --i-data1 /home/roli/FORESTs_BHAVYA/Combined_Libraries/ITS//output/merged.rep.seqs.final.qza --i-data2 /home/roli/FORESTs_BHAVYA/Combined_Libraries/ITS//ITS.rep.seqs.3.qza --o-merged-data /home/roli/FORESTs_BHAVYA/Combined_Libraries/ITS//output/merged.rep.seqs.final.qza\n",
      "\n",
      "qiime feature-table merge --i-table1 /home/roli/FORESTs_BHAVYA/Combined_Libraries/ITS//output/merged.table.final.qza --i-table2 /home/roli/FORESTs_BHAVYA/Combined_Libraries/ITS//ITS.table.4.qza --o-merged-table /home/roli/FORESTs_BHAVYA/Combined_Libraries/ITS//output/merged.table.final.qza\n",
      "\n",
      "qiime feature-table merge-seq-data --i-data1 /home/roli/FORESTs_BHAVYA/Combined_Libraries/ITS//output/merged.rep.seqs.final.qza --i-data2 /home/roli/FORESTs_BHAVYA/Combined_Libraries/ITS//ITS.rep.seqs.4.qza --o-merged-data /home/roli/FORESTs_BHAVYA/Combined_Libraries/ITS//output/merged.rep.seqs.final.qza\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%mkdir $directory/$output\n",
    "\n",
    "for n in range(0, len(qva_files), 1):\n",
    "    if n == 0:\n",
    "        os.system(' '.join([\n",
    "            \"qiime feature-table merge\",\n",
    "            \"--i-table1 \"+directory+\"/\"+qva_files[n],\n",
    "            \"--i-table2 \"+directory+\"/\"+qva_files[n+1],\n",
    "            \"--o-merged-table \"+directory+\"/output/merged.table.final.qza\"\n",
    "        ]))\n",
    "\n",
    "        os.system(' '.join([\n",
    "            \"qiime feature-table merge-seq-data\",\n",
    "            \"--i-data1 \"+directory+\"/\"+seq_files[n],\n",
    "            \"--i-data2 \"+directory+\"/\"+seq_files[n+1],\n",
    "            \"--o-merged-data \"+directory+\"/output/merged.rep.seqs.final.qza\"\n",
    "        ]))\n",
    "    \n",
    "    if n > 0 and n + 1 < len(qva_files):\n",
    "        os.system(' '.join([\n",
    "            \"qiime feature-table merge\",\n",
    "            \"--i-table1 \"+directory+\"/output/merged.table.final.qza\",\n",
    "            \"--i-table2 \"+directory+\"/\"+qva_files[n+1],\n",
    "            \"--o-merged-table \"+directory+\"/output/merged.table.final.qza\"\n",
    "        ]))\n",
    "    \n",
    "        os.system(' '.join([\n",
    "            \"qiime feature-table merge-seq-data\",\n",
    "            \"--i-data1 \"+directory+\"/output/merged.rep.seqs.final.qza\",\n",
    "            \"--i-data2 \"+directory+\"/\"+seq_files[n+1],\n",
    "            \"--o-merged-data \"+directory+\"/output/merged.rep.seqs.final.qza\"\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Create Summary of OTUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qiime feature-table summarize --i-table /home/roli/FORESTs_BHAVYA/HonnedagaLake/raw_seq/ITS//output/ITS.table.qza --o-visualization /home/roli/FORESTs_BHAVYA/HonnedagaLake/raw_seq/ITS//output/ITS.table.qzv --m-sample-metadata-file /home/roli/FORESTs_BHAVYA/HonnedagaLake/raw_seq/ITS/ITS.metadata.tsv\n",
      "qiime feature-table tabulate-seqs --i-data /home/roli/FORESTs_BHAVYA/HonnedagaLake/raw_seq/ITS//output/ITS.rep.seqs.final.qza --o-visualization /home/roli/FORESTs_BHAVYA/HonnedagaLake/raw_seq/ITS//output/ITS.rep.seqs.final.qzv\n"
     ]
    }
   ],
   "source": [
    "os.system(' '.join([\n",
    "    \"qiime feature-table summarize\",\n",
    "    \"--i-table \"+directory+\"/output/merged.table.final.qza\",\n",
    "    \"--o-visualization \"+directory+\"/output/merged.table.final.qzv\",\n",
    "    \"--m-sample-metadata-file \"+directory+metadata\n",
    "]))\n",
    "\n",
    "os.system(' '.join([\n",
    "    \"qiime feature-table tabulate-seqs\",\n",
    "    \"--i-data \"+directory+\"/output/merged.rep.seqs.final.qza\",\n",
    "    \"--o-visualization \"+directory+\"/output/merged.rep.seqs.final.qzv\"\n",
    "])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Make Phylogenetic Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qiime dada2 denoise-paired --i-demultiplexed-seqs /home/roli/FORESTs_BHAVYA/HonnedagaLake/raw_seq/16S//output/SSU.demux.qza --o-table /home/roli/FORESTs_BHAVYA/HonnedagaLake/raw_seq/16S//output/SSU.table --o-representative-sequences /home/roli/FORESTs_BHAVYA/HonnedagaLake/raw_seq/16S//output/SSU.rep.seqs --p-trim-left-f 13 --p-trim-left-r 10 --p-trunc-len-f 240 --p-trunc-len-r 200\n"
     ]
    }
   ],
   "source": [
    "if domain != \"fungi\":\n",
    "    # Generate Alignment with MAFFT\n",
    "    os.system(' '.join([\n",
    "        \"qiime alignment mafft\",\n",
    "        \"--i-sequences \"+directory+\"/output/merged.rep.seqs.final.qza\",\n",
    "        \"--o-alignment \"+directory+\"/output/merged.rep.seqs.aligned.qza\"\n",
    "    ]))\n",
    "\n",
    "    # Mask Hypervariable parts of Alignment\n",
    "    os.system(' '.join([\n",
    "        \"qiime alignment mask\",\n",
    "        \"--i-alignment \"+directory+\"/output/merged.rep.seqs.aligned.qza\",\n",
    "        \"--o-masked-alignment \"+directory+\"/output/merged.rep.seqs.aligned.masked.qza\"\n",
    "    ])) \n",
    "\n",
    "    # Generate Tree with FastTree\n",
    "    os.system(' '.join([\n",
    "        \"qiime phylogeny fasttree\",\n",
    "        \"--i-alignment \"+directory+\"/output/merged.rep.seqs.aligned.masked.qza\",\n",
    "        \"--o-tree \"+directory+\"/output/merged.rep.seqs.tree.unrooted.qza\"\n",
    "    ])) \n",
    "\n",
    "    # Root Tree\n",
    "    os.system(' '.join([\n",
    "        \"qiime phylogeny midpoint-root\",\n",
    "        \"--i-tree \"+directory+\"/output/merged.rep.seqs.tree.unrooted.qza\",\n",
    "        \"--o-rooted-tree \"+directory+\"/output/merged.rep.seqs.tree.final.qza\"\n",
    "    ])) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Classify Seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classify\n",
    "if domain == 'bacteria':\n",
    "    os.system(' '.join([\n",
    "        \"qiime feature-classifier classify-sklearn\",\n",
    "        \"--i-classifier /home/db/GreenGenes/qiime2_13.8.99_515.806_nb.classifier.qza\",\n",
    "        \"--i-reads \"+directory+\"/output/merged.rep.seqs.final.qza\",\n",
    "        \"--o-classification \"+directory+\"/output/merged.taxonomy.final.qza\"\n",
    "    ]))\n",
    "\n",
    "if domain == 'fungi':\n",
    "    os.system(' '.join([\n",
    "        \"qiime feature-classifier classify-sklearn\",\n",
    "        \"--i-classifier /home/db/UNITE/qiime2_unite_ver7.99_20.11.2016_classifier.qza\",\n",
    "        \"--i-reads \"+directory+\"/output/merged.rep.seqs.final.qza\",\n",
    "        \"--o-classification \"+directory+\"/output/merged.taxonomy.final.qza\"\n",
    "    ]))\n",
    "\n",
    "# Output Summary\n",
    "os.system(' '.join([\n",
    "    \"qiime metadata tabulate\",\n",
    "    \"--m-input-file \"+directory+\"/output/merged.taxonomy.final.qza\",\n",
    "    \"--o-visualization \"+directory+\"/output/merged.taxonomy.final.summary.qzv\"\n",
    "])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Prepare Data for Import to Phyloseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Make Function to Re-Format Taxonomy File to Contain Full Column Information \n",
    "# and factor in the certain of the taxonomic assignment\n",
    "\n",
    "def format_taxonomy(tax_file, min_support):\n",
    "    rank_dict = {'k__':\"Domain\",'k__':\"Domain\",}\n",
    "    output = open(re.sub(\".tsv\",\".fixed.tsv\",tax_file), \"w\")\n",
    "    output.write(\"\\t\".join([\"Domain\",\"Phylum\",\"Class\",\"Order\",\"Family\",\"Genus\",\"Species\"])+\"\\n\")\n",
    "    \n",
    "    with open(tax_file, \"r\") as f:\n",
    "        next(f) #skip header\n",
    "        \n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            line = line.split(\"\\t\")\n",
    "            \n",
    "            read_id = line[0]\n",
    "            tax_string = line[1]\n",
    "            \n",
    "            # Annotate those strings which do not meet minimum support\n",
    "            if float(line[2]) < float(min_support):\n",
    "                tax_string = re.sub(\"__\",\"__putative \",tax_string)\n",
    "            \n",
    "            # Remove All Underscore Garbage (gimmie aesthetics)\n",
    "            tax_string = re.sub(\"k__|p__|c__|o__|f__|g__|s__\",\"\",tax_string) \n",
    "            \n",
    "            # Add in columns containing unclassified taxonomic information\n",
    "            # Predicated on maximum 7 ranks (Domain -> Species)\n",
    "            full_rank = tax_string.split(\";\")\n",
    "            last_classified = full_rank[len(full_rank)-1]\n",
    "            \n",
    "            for n in range(len(full_rank), 7, 1):\n",
    "                full_rank.append(\"unclassifed \"+last_classified)\n",
    "                \n",
    "            output.write(read_id+\"\\t\"+'\\t'.join(full_rank)+\"\\n\")\n",
    "            \n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "## Export from QIIME2\n",
    "\n",
    "## Final Output Names\n",
    "fasta_file = directory+\"/output/merged.rep.seqs.final.fasta\"\n",
    "tree_file = directory+\"/output/merged.tree.final.nwk\"\n",
    "tax_file = directory+\"/output/merged.taxonomy.final.tsv\"\n",
    "count_table = directory+\"/output/merged.counts.final.biom\"\n",
    "\n",
    "# Export Classifications\n",
    "os.system(' '.join([\n",
    "    \"qiime tools export\",\n",
    "    directory+\"/output/merged.taxonomy.final.qza\",\n",
    "    \"--output-dir \"+directory+\"/output/\"\n",
    "]))\n",
    "\n",
    "# Reformat Classifications to meet phyloseq format\n",
    "format_taxonomy(directory+\"/output/taxonomy.tsv\", min_support)\n",
    "\n",
    "# Export SV Table\n",
    "os.system(' '.join([\n",
    "    \"qiime tools export\",\n",
    "    directory+\"/output/merged.table.qza\",\n",
    "    \"--output-dir \"+directory+\"/output/\"\n",
    "]))\n",
    "\n",
    "# Export SV Sequences\n",
    "os.system(' '.join([\n",
    "    \"qiime tools export\",\n",
    "    directory+\"/output/merged.rep.seqs.final.qza\",\n",
    "    \"--output-dir \"+directory+\"/output/\"\n",
    "]))\n",
    "\n",
    "# Export Tree\n",
    "os.system(' '.join([\n",
    "    \"qiime tools export\",\n",
    "    directory+\"/output/merged.rep.seqs.tree.final.qza\",\n",
    "    \"--output-dir \"+directory+\"/output/\"\n",
    "]))\n",
    "\n",
    "# Rename Exported Files\n",
    "%mv $directory/output/dna-sequences.fasta $fasta_file\n",
    "%mv $directory/output/feature-table.biom $count_table\n",
    "%mv $directory/output/taxonomy.fixed.tsv $tax_file\n",
    "%mv $directory/output/tree.nwk $tree_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Import into Phyloseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      " \"Hey THERE buckarooooo!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Setup R-Magic for Jupyter Notebooks\n",
    "import rpy2\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "def fix_biom_conversion(file):\n",
    "    with open(file, 'r') as fin:\n",
    "        data = fin.read().splitlines(True)\n",
    "    with open(file, 'w') as fout:\n",
    "        fout.writelines(data[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phyloseq-class experiment-level object\n",
       "otu_table()   OTU Table:         [ 5538 taxa and 192 samples ]\n",
       "sample_data() Sample Data:       [ 192 samples by 585 sample variables ]\n",
       "tax_table()   Taxonomy Table:    [ 5538 taxa by 7 taxonomic ranks ]\n",
       "phy_tree()    Phylogenetic Tree: [ 5538 tips and 5523 internal nodes ]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%R library(phyloseq)\n",
    "%R library(ape)\n",
    "\n",
    "#### IMPORT DATA to R\n",
    "## For '.tsv' files, use Pandas to create a dataframe and then pipe that to R\n",
    "## For '.biom' files, first convert using 'biom convert' on the command-line\n",
    "## Had problems importing the count table with pandas, opted for using read.table in R\n",
    "\n",
    "# Import Taxonomy File\n",
    "tax_file = pd.read_csv(directory+\"/output/merged.taxonomy.final.tsv\", sep=\"\\t\")\n",
    "%%R -i tax_file\n",
    "%%R tax_file <- tax_file[sort(row.names(tax_file)),] #read names must match the count_table\n",
    "\n",
    "# Import Sample Data\n",
    "sample_file = pd.read_csv(directory+metadata, sep=\"\\t\")\n",
    "%%R -i sample_file\n",
    "%%R rownames(sample_file) = sample_file$X.SampleID   \n",
    "%%R sample_file$X.SampleID <- NULL\n",
    "%%R sample_file$LinkerPrimerSequence <- NULL  ## Clean-up some other stuff\n",
    "\n",
    "# Import Count Data\n",
    "os.system(' '.join([\n",
    "    \"biom convert\",\n",
    "    \"-i\",\n",
    "    directory+\"/output/merged.counts.final.biom\",\n",
    "    \"-o\",\n",
    "    directory+\"/output/merged.counts.final.tsv\",\n",
    "    \"--to-tsv\"\n",
    "]))\n",
    "\n",
    "# The biom converter adds a stupid line that messes with the table formatting\n",
    "fix_biom_conversion(directory+\"/output/merged.counts.final.tsv\")\n",
    "\n",
    "# Finally import\n",
    "count_table = pd.read_csv(directory+\"/output/merged.counts.final.tsv\", sep=\"\\t\")\n",
    "%%R -i count_table\n",
    "%%R rownames(count_table) = count_table$X.OTU.ID   \n",
    "%%R count_table$X.OTU.ID <- NULL    \n",
    "%%R count_table <- count_table[sort(row.names(count_table)),] #read names must match the tax_table\n",
    "\n",
    "# Convert to Phyloseq Objects\n",
    "%%R p_counts = otu_table(count_table, taxa_are_rows = TRUE)    \n",
    "%%R p_samples = sample_data(sample_file)    \n",
    "%%R p_tax = tax_table(tax_file)\n",
    "%%R taxa_names(p_tax) <- rownames(tax_file) # phyloseq throws out rownames\n",
    "%%R colnames(p_tax) <- colnames(tax_file) # phyloseq throws out colnames\n",
    "\n",
    "# Merge Phyloseq Objects\n",
    "%%R p = phyloseq(p_counts, p_tax)\n",
    "\n",
    "# Import Phylogenetic Tree\n",
    "tree_file = directory+\"/output/merged.tree.final.nwk\"\n",
    "%%R -i tree_file  \n",
    "%%R p_tree <- read.tree(tree_file)\n",
    "\n",
    "# Combine All Objects into One Phyloseq\n",
    "%%R p_final <- merge_phyloseq(p, p_samples, p_tree)\n",
    "\n",
    "# Save Phyloseq Object as '.rds'\n",
    "output = directory+\"/output/p_merged.final.rds\"\n",
    "%%R -i output\n",
    "%%R saveRDS(p_final, file = output)\n",
    "\n",
    "# Confirm Output\n",
    "%%R print(p_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Clean-up Intermediate Files and Final Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your sequences have been successfully saved to 'final' and 'intermediate_files'\n"
     ]
    }
   ],
   "source": [
    "# Remove Files\n",
    "%rm $directory/output/*tree.unrooted.qza \n",
    "%rm $directory/output/*aligned.masked.qza \n",
    "%rm $directory/output/*.biom \n",
    "%rm $directory/output/*barcodes.fastq.gz \n",
    "%rm $directory/output/taxonomy.tsv\n",
    "%rm $directory/output/forward.fastq.gz # Just the symlink\n",
    "%rm $directory/output/reverse.fastq.gz # Just the symlink\n",
    "\n",
    "# Separate Final Files\n",
    "%mkdir $directory/final/    \n",
    "%mv $directory/output/*.final.rds $directory/final/\n",
    "%mv $directory/output/*.taxonomy.final.tsv $directory/final/    \n",
    "%mv $directory/output/*.counts.final.tsv $directory/final/\n",
    "%mv $directory/output/*.final.fasta $directory/final/\n",
    "%cp $directory$metadata $directory/final/\n",
    "\n",
    "# Gzip and Move Intermediate Files\n",
    "!pigz -p 10 $directory/output/*.qza\n",
    "!pigz -p 10 $directory/output/*.qzv\n",
    "%mv $directory/output/ $directory/intermediate_files\n",
    "\n",
    "print(\"Your sequences have been successfully saved to directories 'final' and 'intermediate_files'\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": true,
  "kernelspec": {
   "display_name": "Environment (conda_qiime2-2017.9)",
   "language": "python",
   "name": "conda_qiime2-2017.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
